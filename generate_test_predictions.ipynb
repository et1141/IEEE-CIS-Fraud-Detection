{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 394)\n",
      "(144233, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "VERBOSE = True \n",
    "R_S = 42\n",
    "VAL_SIZE = 0.2\n",
    "VIF_DELETE_THRESH=10\n",
    "MISSING_THRESH=0.9\n",
    "\n",
    "RESULTS_JSON = \"models/results.json\"\n",
    "MODEL_PATH = \"models/lgbm_num_cat_te_31.pkl\"\n",
    "MODEL_ID_FILE = \"models/model_id.txt\"\n",
    "\n",
    "train_transaction = pd.read_csv(f\"{DATA_PATH}/train_transaction.csv\")\n",
    "train_identity = pd.read_csv(f\"{DATA_PATH}/train_identity.csv\")\n",
    "print(train_transaction.shape)\n",
    "print(train_identity.shape)\n",
    "\n",
    "\n",
    "# Merge the transaction, identity tables\n",
    "# left join because: \"Not all transactions have corresponding identity information.\"\n",
    "\n",
    "train_df = train_transaction.merge(\n",
    "    train_identity,\n",
    "    on=\"TransactionID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "y = train_df[\"isFraud\"]\n",
    "X = train_df.drop(columns=[\"isFraud\"])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=R_S,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad577b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Preprocessing the train set...\n",
      "   Test data loaded. Shape: (472432, 422)\n",
      "2. Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/machine_learning/lib/python3.14/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/machine_learning/lib/python3.14/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/machine_learning/lib/python3.14/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"models/lgbm_num_cat_te_31.pkl\"\n",
    "\n",
    "print(\"1. Preprocessing the train set...\")\n",
    "\n",
    "X_train_num = X_train.select_dtypes(include=[\"number\"]).copy()\n",
    "if \"TransactionID\" in X_train_num.columns:\n",
    "    X_train_num.drop(columns=[\"TransactionID\"], inplace=True)\n",
    "\n",
    "missing_rate = X_train_num.isna().mean()\n",
    "keep_cols = missing_rate[missing_rate <= MISSING_THRESH].index.tolist()\n",
    "X_train_num_filtered = X_train_num[keep_cols]\n",
    "\n",
    "X_train_cat = X_train.select_dtypes(include=[\"object\", \"category\"]).copy()\n",
    "cat_cols = X_train_cat.columns.tolist()\n",
    "X_train_cat = X_train_cat.fillna(\"__MISSING__\")\n",
    "\n",
    "te = TargetEncoder(cols=cat_cols)\n",
    "X_train_cat_encoded = te.fit_transform(X_train_cat, y_train)\n",
    "\n",
    "X_train_final = X_train_num_filtered.join(X_train_cat_encoded)\n",
    "\n",
    "print(f\"   Test data loaded. Shape: {X_train_final.shape}\")\n",
    "\n",
    "print(\"2. Loading the model...\")\n",
    "old_pipeline = joblib.load(MODEL_PATH)\n",
    "trained_model = old_pipeline.named_steps['clf']\n",
    "new_imputer = SimpleImputer(strategy=\"median\")\n",
    "new_imputer.fit(X_train_final)\n",
    "\n",
    "print(\"3. Preprocessing the test set..\")\n",
    "\n",
    "test_transaction = pd.read_csv(f\"{DATA_PATH}/test_transaction.csv\")\n",
    "test_identity = pd.read_csv(f\"{DATA_PATH}/test_identity.csv\")\n",
    "\n",
    "test_identity.columns = [c.replace('-', '_') for c in test_identity.columns]\n",
    "\n",
    "X_test = test_transaction.merge(test_identity, on=\"TransactionID\", how=\"left\")\n",
    "test_ids = X_test[\"TransactionID\"]\n",
    "\n",
    "X_test_num = X_test.select_dtypes(include=[\"number\"])\n",
    "for col in keep_cols:\n",
    "    if col not in X_test_num.columns:\n",
    "        X_test_num[col] = np.nan\n",
    "X_test_num = X_test_num[keep_cols].copy()\n",
    "\n",
    "# arget Encoding\n",
    "X_test_cat = X_test.select_dtypes(include=[\"object\", \"category\"]).copy()\n",
    "for col in cat_cols:\n",
    "    if col not in X_test_cat.columns:\n",
    "        X_test_cat[col] = \"__MISSING__\"\n",
    "X_test_cat = X_test_cat[cat_cols].fillna(\"__MISSING__\")\n",
    "X_test_cat_encoded = te.transform(X_test_cat)\n",
    "\n",
    "X_test_final = X_test_num.join(X_test_cat_encoded)\n",
    "print(f\"   Dane testowe gotowe. Shape: {X_test_final.shape}\")\n",
    "\n",
    "\n",
    "print(\"4. Generating predictions...\")\n",
    "X_test_imputed = new_imputer.transform(X_test_final)\n",
    "\n",
    "predictions = trained_model.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'TransactionID': test_ids,\n",
    "    'isFraud': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Success! The file  'submission.csv' was saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
